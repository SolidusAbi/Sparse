{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "project_dir = os.path.join(os.getcwd(),'..')\n",
    "if project_dir not in sys.path:\n",
    "    sys.path.append(project_dir)\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import Compose, ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = Compose([ToTensor(), nn.Flatten(start_dim=0)])\n",
    "dataset = MNIST('../dataset', transform=transform, download=True)\n",
    "loader = DataLoader(dataset, batch_size=128)\n",
    "x, y = next(iter(loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Sparse import SparseWeights, KWinners\n",
    "\n",
    "model = nn.Sequential(*[\n",
    "    SparseWeights(nn.Linear(28*28, 128), weightSparsity=.4),\n",
    "    KWinners(128, 64),\n",
    "    nn.BatchNorm1d(128),\n",
    "    SparseWeights(nn.Linear(128, 64), weightSparsity=.4),\n",
    "    KWinners(64, 32),\n",
    "    nn.BatchNorm1d(64),\n",
    "    nn.Linear(64, 10),\n",
    "    nn.LogSoftmax(dim=1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "n_epoch = 10\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "epoch_iterator = tqdm(\n",
    "        range(n_epoch),\n",
    "        leave=True,\n",
    "        unit=\"epoch\",\n",
    "        postfix={\"tls\": \"%.4f\" % 1},\n",
    "    )\n",
    "\n",
    "for epoch in epoch_iterator:\n",
    "    for input, target in loader:\n",
    "        input = input.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        out = model(input)\n",
    "        loss = criterion(out, target)\n",
    "\n",
    "        epoch_iterator.set_postfix(tls=\"%.4f\" % np.mean(loss.detach().item()))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "bins = np.linspace(0.0, 0.03, 25)\n",
    "plt.hist((model[1].dutyCycle / 32).cpu().numpy(), bins=25)\n",
    "plt.title(\"Histogram of duty cycles, entropy=\" + str(float(model[1].entropy())))\n",
    "plt.xlabel(\"Duty cycle\")\n",
    "plt.ylabel(\"Number of units\")\n",
    "print('Max entropy: {}'.format(model[1].maxEntropy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1d9b8aa8d774518be7ebcfd06a2463a8035a66798fac49b1a363f570d2d8622e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('DeepLearning': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
