{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "project_dir = os.path.join(os.getcwd(),'..')\n",
    "if project_dir not in sys.path:\n",
    "    sys.path.append(project_dir)\n",
    "\n",
    "from Sparse.modules.variational import LinearCD\n",
    "from Sparse.modules.variational import VariationalLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function \n",
    "from Sparse.modules.variational import VariationalLayer\n",
    "from torch.nn.functional import cross_entropy\n",
    "from torch import nn\n",
    "class SGVBL(nn.Module):\n",
    "    ''' \n",
    "        Stocastich Gradient Variational Bayes (SGVB) Loss function.\n",
    "        More details in https://arxiv.org/pdf/1506.02557.pdf and https://arxiv.org/pdf/1312.6114.pdf\n",
    "    '''\n",
    "\n",
    "    def __init__(self, model, train_size, loss=cross_entropy):\n",
    "        super(SGVBL, self).__init__()\n",
    "        self.train_size = train_size\n",
    "        self.net = model\n",
    "        self.loss = loss\n",
    "\n",
    "        self.variational_layers = []\n",
    "        for module in model.modules():\n",
    "            if isinstance(module, (VariationalLayer)):\n",
    "                self.variational_layers.append(module)\n",
    "\n",
    "    def forward(self, input, target, kl_weight=1.0):\n",
    "        assert not target.requires_grad\n",
    "        kl = 0.0\n",
    "        for layer in self.variational_layers:\n",
    "            kl += layer.kl_reg()\n",
    "        \n",
    "        # return self.loss(input, target) * self.train_size + kl_weight * kl    \n",
    "        return self.loss(target, *input) * self.train_size + kl_weight * kl # Lo vi en concrete dropout que el kl_weight es 1/train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, nb_features, weight_reg, drop_reg):\n",
    "        super(Model, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            LinearCD(1, nb_features//2, bias=False, w_reg=weight_reg, drop_reg=drop_reg),\n",
    "            nn.ReLU6(),\n",
    "            LinearCD(nb_features//2, nb_features, w_reg=weight_reg, drop_reg=drop_reg),\n",
    "            nn.ReLU6(),\n",
    "            LinearCD(nb_features, nb_features, w_reg=weight_reg, drop_reg=drop_reg),\n",
    "            nn.ReLU6(),\n",
    "        )\n",
    "\n",
    "        self.mu = LinearCD(nb_features, 1, w_reg=weight_reg, drop_reg=drop_reg)\n",
    "        self.log_var = LinearCD(nb_features, 1, w_reg=weight_reg, drop_reg=drop_reg)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.features(x)\n",
    "        mu = self.mu(h)\n",
    "        log_var = self.log_var(h)\n",
    "        return mu, log_var\n",
    "\n",
    "def heteroscedastic_loss(true, mean, log_var):\n",
    "    # Heteroscedatic, variation error is not constant during the samples.\n",
    "    precision = torch.exp(-log_var)\n",
    "    return torch.mean(torch.sum(precision * (true - mean)**2 + log_var, 1), 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Original Experiment\n",
    "... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "Ns = [10, 25, 50, 100, 1000, 10000] # Number of data points\n",
    "Ns = np.array(Ns)\n",
    "nb_epochs = [2000, 1000, 500, 200, 20, 2]\n",
    "nb_val_size = 1000 # Validation size\n",
    "nb_features = 1024 # Hidden layer size\n",
    "Q = 1 # Data dimensionality\n",
    "D = 1 # One mean, one log_var\n",
    "K_test = 20 # Number of MC samples\n",
    "nb_reps = 3 # Number of times to repeat experiment\n",
    "batch_size = 64\n",
    "l = 1e-6 # Lengthscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_data(N):\n",
    "    \"\"\"\n",
    "        Function to generate data\n",
    "    \"\"\"\n",
    "    sigma = 1e0  # ground truth\n",
    "    X = np.random.randn(N, Q)\n",
    "    w = 2.\n",
    "    b = 8.\n",
    "    Y = X.dot(w) + b + sigma * np.random.randn(N, D)\n",
    "    return X, Y\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "X, Y = gen_data(10)\n",
    "plt.scatter(X[:, 0], Y[:, 0], edgecolor='b')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "X, Y = gen_data(10000)\n",
    "plt.scatter(X[:, 0], Y[:, 0], edgecolor='b')\n",
    "plt.xlim([-5, 5])\n",
    "plt.ylim([-2, 20])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "def fit_model(nb_epoch, X, Y):\n",
    "    N = X.shape[0]\n",
    "    wr = l**2.\n",
    "    dr = 2.\n",
    "    model = Model(nb_features, wr, dr)\n",
    "    model = model.cuda()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "    criterion = SGVBL(model, N, loss=heteroscedastic_loss)\n",
    "    kl_weight = .6\n",
    "\n",
    "    epoch_iterator = tqdm(\n",
    "            range(nb_epoch),\n",
    "            leave=True,\n",
    "            unit=\"epoch\",\n",
    "            postfix={\"tls\": \"%.4f\" % 1},\n",
    "        )\n",
    "\n",
    "    for epoch in epoch_iterator:\n",
    "        old_batch = 0\n",
    "        kl_weight = min(kl_weight + 1e-2, 1.0)\n",
    "        for batch in range(int(np.ceil(X.shape[0]/batch_size))):\n",
    "            batch = (batch + 1)\n",
    "            _x = X[old_batch: batch_size*batch]\n",
    "            _y = Y[old_batch: batch_size*batch]\n",
    "            \n",
    "            x = Variable(torch.FloatTensor(_x)).cuda()\n",
    "            y = Variable(torch.FloatTensor(_y)).cuda()\n",
    "            \n",
    "            output = model(x)\n",
    "            loss = criterion(output, y, kl_weight)\n",
    "             \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if batch % 10 == 0:\n",
    "                epoch_iterator.set_postfix(tls=\"%.4f\" % loss.detach().item())\n",
    "\n",
    "        # print(loss.detach().item())\n",
    "            \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = Ns[4]\n",
    "X, Y = gen_data(N + nb_val_size)\n",
    "X_train, Y_train = X[:N], Y[:N]\n",
    "X_val, Y_val = X[N:], Y[N:]\n",
    "model = fit_model(50, X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot2(X_train, Y_train, X_val, Y_val, means):\n",
    "    indx = np.argsort(X_val[:, 0])\n",
    "    _, (ax1, ax2, ax3, ax4) = plt.subplots(1, 4,figsize=(12, 1.5), sharex=True, sharey=True)\n",
    "    ax1.scatter(X_train[:, 0], Y_train[:, 0], c='y')\n",
    "    ax1.set_title('Train set')\n",
    "    ax2.plot(X_val[indx, 0], np.mean(means, 0)[indx], color='skyblue', lw=3)\n",
    "    ax2.scatter(X_train[:, 0], Y_train[:, 0], c='y')\n",
    "    ax2.set_title('+Predictive mean')\n",
    "    for mean in means:\n",
    "        ax3.scatter(X_val[:, 0], mean, c='b', alpha=0.2, lw=0)\n",
    "    ax3.plot(X_val[indx, 0], np.mean(means, 0)[indx], color='skyblue', lw=3)\n",
    "    ax3.set_title('+MC samples on validation X')\n",
    "    ax4.scatter(X_val[:, 0], Y_val[:, 0], c='r', alpha=0.2, lw=0)\n",
    "    ax4.set_title('Validation set')\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def logsumexp(a):\n",
    "    a_max = a.max(axis=0)\n",
    "    return np.log(np.sum(np.exp(a - a_max), axis=0)) + a_max\n",
    "\n",
    "def test(Y_true, K_test, means, logvar):\n",
    "    \"\"\"\n",
    "    Estimate predictive log likelihood:\n",
    "    log p(y|x, D) = log int p(y|x, w) p(w|D) dw\n",
    "                 ~= log int p(y|x, w) q(w) dw\n",
    "                 ~= log 1/K sum p(y|x, w_k) with w_k sim q(w)\n",
    "                  = LogSumExp log p(y|x, w_k) - log K\n",
    "    :Y_true: a 2D array of size N x dim\n",
    "    :MC_samples: a 3D array of size samples K x N x 2*D\n",
    "    \"\"\"\n",
    "    k = K_test\n",
    "    N = Y_true.shape[0]\n",
    "    mean = means \n",
    "    logvar = logvar\n",
    "    test_ll = -0.5 * np.exp(-logvar) * (mean - Y_val.squeeze())**2. - 0.5 * logvar - 0.5 * np.log(2 * np.pi) #Y_true[None]\n",
    "    test_ll = np.sum(np.sum(test_ll, -1), -1)\n",
    "    test_ll = logsumexp(test_ll) - np.log(k)\n",
    "    pppp = test_ll / N  # per point predictive probability\n",
    "    rmse = np.mean((np.mean(mean, 0) - Y_val.squeeze())**2.)**0.5\n",
    "    return pppp, rmse\n",
    "\n",
    "\n",
    "rep_results = []\n",
    "model.train()\n",
    "# model.eval()\n",
    "MC_samples = [model(Variable(torch.FloatTensor(X_val)).cuda()) for _ in range(K_test)]\n",
    "means = torch.stack([tup[0] for tup in MC_samples]).view(K_test, X_val.shape[0]).cpu().data.numpy()\n",
    "logvar = torch.stack([tup[1] for tup in MC_samples]).view(K_test, X_val.shape[0]).cpu().data.numpy()\n",
    "pppp, rmse = test(Y_val, K_test, means, logvar)\n",
    "epistemic_uncertainty = np.var(means, 0).mean(0)\n",
    "logvar = np.mean(logvar, 0)\n",
    "aleatoric_uncertainty = np.exp(logvar).mean(0)\n",
    "ps = np.array([torch.sigmoid(module.p_logit).cpu().data.numpy()[0] for module in model.modules() if hasattr(module, 'p_logit')])\n",
    "plot(X_train, Y_train, X_val, Y_val, means)\n",
    "rep_results += [(rmse, ps, aleatoric_uncertainty, epistemic_uncertainty)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.sigmoid(model.features[0].logit_p).mean())\n",
    "print(torch.sigmoid(model.features[2].logit_p).mean())\n",
    "print(torch.sigmoid(model.features[4].logit_p).mean())\n",
    "print(torch.sigmoid(model.mu.logit_p).mean())\n",
    "print(torch.sigmoid(model.log_var.logit_p).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Breast Cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "project_dir = os.path.join(os.getcwd(),'..')\n",
    "if project_dir not in sys.path:\n",
    "    sys.path.append(project_dir)\n",
    "\n",
    "from Sparse.modules.variational import LinearCD\n",
    "from Sparse.modules.variational.utils import SGVBL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.functional import one_hot\n",
    "\n",
    "class BreastCancer(Dataset):\n",
    "    r'''\n",
    "        Breast Cancer Wisconsin Dataset\n",
    "    '''\n",
    "    def __init__(self, normalize=False):\n",
    "        dataset = datasets.load_breast_cancer()\n",
    "        self.data = torch.tensor(dataset.data).float()\n",
    "        self.targets = torch.tensor(dataset.target)\n",
    "    \n",
    "        if normalize:\n",
    "            self.data /= torch.max(self.data, dim=0)[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.targets[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, nb_features, weight_reg, drop_reg):\n",
    "        super(Model, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            LinearCD(30, nb_features, w_reg=weight_reg, drop_reg=drop_reg),\n",
    "            nn.ReLU(),\n",
    "            LinearCD(nb_features, nb_features//2, w_reg=weight_reg, drop_reg=drop_reg),\n",
    "            nn.ReLU(),\n",
    "            LinearCD(nb_features//2, 2, w_reg=weight_reg, drop_reg=drop_reg)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = BreastCancer(normalize=True)\n",
    "loader = DataLoader(dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from torch.nn.functional import cross_entropy\n",
    "\n",
    "def train(model, dataset, batch_size = 64, n_epochs=10):\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model = model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    criterion = SGVBL(model, len(dataset), cross_entropy)\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    kl_weight = 1e-2\n",
    "\n",
    "    epoch_iterator = tqdm(\n",
    "            range(n_epochs),\n",
    "            leave=True,\n",
    "            unit=\"epoch\",\n",
    "            postfix={\"tls\": \"%.4f\" % 1},\n",
    "        )\n",
    "\n",
    "    for _ in epoch_iterator:\n",
    "        kl_weight = min(kl_weight + 0.02, 1.0)\n",
    "        for idx, (inputs, targets) in enumerate(loader):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            pred = model(inputs)\n",
    "\n",
    "            loss = criterion(pred, targets, kl_weight)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if idx % 10 == 0:\n",
    "                epoch_iterator.set_postfix(tls=\"%.4f\" % loss.item())\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = 1e-2 # Lengthscale\n",
    "w_reg = l**2 \n",
    "d_reg = 1\n",
    "\n",
    "model = Model(512, w_reg, d_reg)\n",
    "model = train(model, dataset, n_epochs=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(torch.sigmoid(model.model[0].logit_p) < .4).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "x, y = next(iter(loader))\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_samples = 1000\n",
    "samples = []\n",
    "model.eval()\n",
    "model.train()\n",
    "with torch.no_grad():\n",
    "    for i in range(mc_samples):\n",
    "        samples.append(torch.softmax(model(x.cuda()), dim=1).cpu())\n",
    "\n",
    "test = torch.stack(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt \n",
    "samples_idx = 4\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(test[:, samples_idx, 0].detach().cpu().numpy(), label='0')\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(test[:, samples_idx, 1].detach().cpu().numpy(), label='1')\n",
    "plt.title('Target: {}'.format(y[samples_idx]))\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_score, index = torch.sigmoid(model.model[0].logit_p).sort()\n",
    "\n",
    "features_names = datasets.load_breast_cancer(as_frame=True).data.columns[index.cpu()]\n",
    "\n",
    "print('Features:{}'.format(features_names))\n",
    "print('Features Score:{}'.format(features_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('HySpecLab')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bc81a3ec444beb1d5a523daf231afa571e79be8a57abb6fe0028623a3d4d7136"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
