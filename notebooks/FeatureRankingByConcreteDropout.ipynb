{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "project_dir = os.path.join(os.getcwd(),'..')\n",
    "if project_dir not in sys.path:\n",
    "    sys.path.append(project_dir)\n",
    "\n",
    "from Sparse.modules.variational import LinearCD\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "class LinearCD(nn.Linear):\n",
    "    r'''\n",
    "        Linear layer with Concrete Dropout regularization.\n",
    "\n",
    "        Code strongly inspired by: \n",
    "            https://github.com/danielkelshaw/ConcreteDropout/blob/master/condrop/concrete_dropout.py\n",
    "\n",
    "        Note the relationship between the weight regularizer (w_reg) and dropout regularization (drop_reg):\n",
    "        \n",
    "            w_reg/drop_reg = (l^2)/2 \n",
    "        \n",
    "        with prior lengthscale l (number of in_features). \n",
    "        \n",
    "        Note also that the factor of two should be ignored for cross-entropy loss, and used only for the\n",
    "        Euclidean loss.\n",
    "    '''\n",
    "    def __init__(self, in_features, out_features, bias=True, threshold=.95, init_min=0.5, init_max=0.51):\n",
    "        super(LinearCD, self).__init__(in_features, out_features, bias)        \n",
    "        logit_init_min = np.log(init_min) - np.log(1. - init_min)\n",
    "        logit_init_max = np.log(init_max) - np.log(1. - init_max)\n",
    "        \n",
    "        # The probability of deactive a neuron.\n",
    "        self.logit_p = nn.Parameter(torch.rand(in_features) * (logit_init_max - logit_init_min) + logit_init_min)\n",
    "        self.logit_threshold = np.log(threshold) - np.log(1. - threshold)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.training:\n",
    "            return F.linear(self.concrete_bernoulli(x), self.weight, self.bias)\n",
    "\n",
    "        return F.linear(x, self.weight * (self.logit_p < self.logit_threshold).float(), self.bias) \n",
    "\n",
    "    def concrete_bernoulli(self, x):\n",
    "        eps = 1e-8\n",
    "        unif_noise = torch.cuda.FloatTensor(*x.size()).uniform_() if self.logit_p.is_cuda else torch.FloatTensor(*x.size()).uniform_()\n",
    "\n",
    "        p = torch.sigmoid(self.logit_p)\n",
    "        tmp = .1\n",
    "\n",
    "        drop_prob = (torch.log(p + eps) - torch.log((1-p) + eps) + torch.log(unif_noise + eps)\n",
    "        - torch.log((1. - unif_noise) + eps))\n",
    "        drop_prob = torch.sigmoid(drop_prob / tmp)\n",
    "\n",
    "        random_tensor = 1 - drop_prob\n",
    "        retain_prob = 1 - p # rescale factor typical for dropout\n",
    "\n",
    "        if self.training:\n",
    "            self.activation_reg = random_tensor.sum(dim=1).mean() # Penalizing the number of features activated\n",
    "\n",
    "        return torch.mul(x, random_tensor)\n",
    "\n",
    "    def reg(self):\n",
    "        return self.activation_reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Breast Cancer Wisconsin Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class BreastCancer(Dataset):\n",
    "    r'''\n",
    "        Breast Cancer Wisconsin Dataset\n",
    "    '''\n",
    "    def __init__(self, normalize=False):\n",
    "        dataset = datasets.load_breast_cancer()\n",
    "        self.data = torch.tensor(dataset.data).float()\n",
    "        self.targets = torch.tensor(dataset.target)\n",
    "    \n",
    "        if normalize:\n",
    "            self.data /= torch.max(self.data, dim=0)[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.targets[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, nb_features, threshold = .75):\n",
    "        super(Model, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            LinearCD(30, nb_features, bias=False, threshold=threshold),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(nb_features, nb_features//2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(nb_features//2, 2)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = BreastCancer(normalize=True)\n",
    "\n",
    "eval_len = len(dataset) // 5 # 20% of the dataset\n",
    "train_set, eval_set = torch.utils.data.random_split(dataset, [len(dataset) - eval_len, eval_len])\n",
    "\n",
    "loader = DataLoader(eval_set, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def train(model, dataset, batch_size = 128, n_epochs=10):\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model = model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    reg = 1e-6\n",
    "\n",
    "    epoch_iterator = tqdm(\n",
    "            range(n_epochs),\n",
    "            leave=True,\n",
    "            unit=\"epoch\",\n",
    "            postfix={\"tls\": \"%.4f\" % 1},\n",
    "        )\n",
    "\n",
    "    modules = []\n",
    "    for i in model.modules():\n",
    "        if isinstance(i, LinearCD):\n",
    "            modules.append(i)\n",
    "\n",
    "    for _ in epoch_iterator:\n",
    "        reg = min(reg + .1e-4, 5e-2)\n",
    "        for idx, (inputs, targets) in enumerate(loader):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            pred = model(inputs)\n",
    "\n",
    "            reg_value = 0\n",
    "            for module in modules:\n",
    "                reg_value += module.reg()\n",
    "\n",
    "            loss = criterion(pred, targets) + reg*reg_value\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if idx % 10 == 0:\n",
    "                epoch_iterator.set_postfix(tls=\"%.4f\" % loss.item())\n",
    "\n",
    "    print(reg)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:09<00:00, 53.40epoch/s, tls=0.1820]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.005000999999999965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = Model(512, threshold=.75)\n",
    "model = train(model, train_set, n_epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True, False,  True, False, False,  True,  True, False,\n",
       "        True,  True, False,  True,  True, False,  True,  True, False,\n",
       "       False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True, False])"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sigmoid(model.model[0].logit_p).data.cpu().numpy() < .5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:['worst area' 'area error' 'mean concave points' 'worst concave points'\n",
      " 'mean concavity' 'mean area' 'mean fractal dimension' 'concavity error'\n",
      " 'worst perimeter' 'worst compactness' 'worst texture' 'mean texture'\n",
      " 'worst concavity' 'worst radius' 'fractal dimension error' 'radius error'\n",
      " 'compactness error' 'worst smoothness' 'worst symmetry' 'perimeter error'\n",
      " 'mean radius' 'mean perimeter' 'smoothness error' 'mean smoothness'\n",
      " 'mean symmetry' 'symmetry error' 'mean compactness' 'texture error'\n",
      " 'concave points error' 'worst fractal dimension']\n",
      "Features Score:tensor([0.3493, 0.3732, 0.3772, 0.3806, 0.4115, 0.4185, 0.4258, 0.4310, 0.4372,\n",
      "        0.4438, 0.4445, 0.4451, 0.4456, 0.4488, 0.4500, 0.4536, 0.4812, 0.4842,\n",
      "        0.4843, 0.4861, 0.4898, 0.5139, 0.5196, 0.5216, 0.5275, 0.5303, 0.5307,\n",
      "        0.5345, 0.5371, 0.5551], device='cuda:0', grad_fn=<SortBackward0>)\n"
     ]
    }
   ],
   "source": [
    "features_score, index = torch.sigmoid(model.model[0].logit_p).sort()\n",
    "\n",
    "features_names = datasets.load_breast_cancer(as_frame=True).data.columns[index.cpu()]\n",
    "\n",
    "print('Features:{}'.format(features_names))\n",
    "print('Features Score:{}'.format(features_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3944691740.py, line 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_4217/3944691740.py\"\u001b[0;36m, line \u001b[0;32m10\u001b[0m\n\u001b[0;31m    Features Score:tensor([0.1855, 0.2411, 0.2672, 0.2806, 0.2903, 0.2936, 0.2979, 0.3000, 0.3354,\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Features:['area error' 'mean concave points' 'worst concavity' 'mean concavity'\n",
    " 'worst area' 'worst concave points' 'fractal dimension error'\n",
    " 'compactness error' 'worst smoothness' 'mean compactness'\n",
    " 'worst compactness' 'mean texture' 'concave points error' 'mean area'\n",
    " 'mean radius' 'radius error' 'mean symmetry' 'worst texture'\n",
    " 'mean perimeter' 'smoothness error' 'mean smoothness' 'worst radius'\n",
    " 'mean fractal dimension' 'texture error' 'worst perimeter'\n",
    " 'worst fractal dimension' 'symmetry error' 'worst symmetry'\n",
    " 'perimeter error' 'concavity error']\n",
    "Features Score:tensor([0.1855, 0.2411, 0.2672, 0.2806, 0.2903, 0.2936, 0.2979, 0.3000, 0.3354,\n",
    "        0.3424, 0.3433, 0.3501, 0.3506, 0.3542, 0.3587, 0.3588, 0.3607, 0.3622,\n",
    "        0.3638, 0.3640, 0.3642, 0.3652, 0.3667, 0.3734, 0.3784, 0.3801, 0.3804,\n",
    "        0.3987, 0.4080, 0.4085], device='cuda:0', grad_fn=<SortBackward0>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1,\n",
       "        1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0,\n",
       "        0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1,\n",
       "        0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "        0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold = .6\n",
    "model.model[0].logit_threshold = torch.tensor(np.log(threshold) - np.log(1. - threshold))\n",
    "model.eval()\n",
    "torch.argmax(torch.softmax(model(x.cuda()), dim=1), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1,\n",
       "        1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0,\n",
       "        0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "        0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1,\n",
       "        0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9646, device='cuda:0')"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(torch.argmax(torch.softmax(model(x.cuda()), dim=1), dim=1) == y.cuda()).sum() / len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "569"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(569 * .2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "569 // 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0150, -0.0165, -0.0161, -0.0251, -0.0167, -0.0141, -0.0267, -0.0231,\n",
       "        -0.0137, -0.0221, -0.0198, -0.0128, -0.0275, -0.0310, -0.0075, -0.0228,\n",
       "        -0.0126, -0.0235, -0.0144, -0.0143, -0.0109, -0.0138, -0.0307, -0.0285,\n",
       "        -0.0140, -0.0238, -0.0226, -0.0229, -0.0124, -0.0095], device='cuda:0',\n",
       "       grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model[0].weight.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('HySpecLab')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bc81a3ec444beb1d5a523daf231afa571e79be8a57abb6fe0028623a3d4d7136"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
