{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "project_dir = os.path.join(os.getcwd(),'..')\n",
    "if project_dir not in sys.path:\n",
    "    sys.path.append(project_dir)\n",
    "\n",
    "from Sparse.modules.variational import LinearCD\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "class LinearCD(nn.Linear):\n",
    "    r'''\n",
    "        Linear layer with Concrete Dropout regularization.\n",
    "\n",
    "        Code strongly inspired by: \n",
    "            https://github.com/danielkelshaw/ConcreteDropout/blob/master/condrop/concrete_dropout.py\n",
    "\n",
    "        Note the relationship between the weight regularizer (w_reg) and dropout regularization (drop_reg):\n",
    "        \n",
    "            w_reg/drop_reg = (l^2)/2 \n",
    "        \n",
    "        with prior lengthscale l (number of in_features). \n",
    "        \n",
    "        Note also that the factor of two should be ignored for cross-entropy loss, and used only for the\n",
    "        Euclidean loss.\n",
    "    '''\n",
    "    def __init__(self, in_features, out_features, bias=True, threshold=.1, init_min=.5, init_max=.5):\n",
    "        super(LinearCD, self).__init__(in_features, out_features, bias)        \n",
    "        logit_init_min = np.log(init_min) - np.log(1. - init_min)\n",
    "        logit_init_max = np.log(init_max) - np.log(1. - init_max)\n",
    "        \n",
    "        # The probability of deactive a neuron.\n",
    "        self.logit_p = nn.Parameter(torch.rand(in_features) * (logit_init_max - logit_init_min) + logit_init_min)\n",
    "        self.logit_threshold = np.log(threshold) - np.log(1. - threshold)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.training:\n",
    "            return F.linear(self.concrete_bernoulli(x), self.weight, self.bias)\n",
    "\n",
    "        return F.linear(x, self.weight * (self.logit_p < self.logit_threshold).float(), self.bias) \n",
    "\n",
    "    def concrete_bernoulli(self, x):\n",
    "        eps = 1e-8\n",
    "        unif_noise = torch.cuda.FloatTensor(*x.size()).uniform_() if self.logit_p.is_cuda else torch.FloatTensor(*x.size()).uniform_()\n",
    "\n",
    "        p = torch.sigmoid(self.logit_p)\n",
    "        tmp = .1\n",
    "\n",
    "        drop_prob = (torch.log(p + eps) - torch.log((1-p) + eps) + torch.log(unif_noise + eps)\n",
    "        - torch.log((1. - unif_noise) + eps))\n",
    "        drop_prob = torch.sigmoid(drop_prob / tmp)\n",
    "\n",
    "        random_tensor = 1 - drop_prob\n",
    "        retain_prob = 1 - p # rescale factor typical for dropout\n",
    "\n",
    "        return torch.mul(x, random_tensor)\n",
    "\n",
    "    def reg(self):\n",
    "        tmp = .1\n",
    "        eps = 1e-6\n",
    "        p = torch.sigmoid(self.logit_p)\n",
    "        bernoulli = (torch.log(p + eps) - torch.log((1-p) + eps))\n",
    "        reg = 1 - torch.sigmoid(bernoulli / tmp)\n",
    "        return torch.sum(reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Breast Cancer Wisconsin Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class BreastCancer(Dataset):\n",
    "    r'''\n",
    "        Breast Cancer Wisconsin Dataset\n",
    "    '''\n",
    "    def __init__(self, normalize=False):\n",
    "        dataset = datasets.load_breast_cancer()\n",
    "        self.data = torch.tensor(dataset.data).float()\n",
    "        self.targets = torch.tensor(dataset.target)\n",
    "    \n",
    "        if normalize:\n",
    "            self.data /= torch.max(self.data, dim=0)[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.targets[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, nb_features, threshold = .75):\n",
    "        super(Model, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            LinearCD(30, nb_features, bias=False, threshold=threshold),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(nb_features, nb_features//2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(nb_features//2, 2)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = BreastCancer(normalize=True)\n",
    "\n",
    "eval_len = len(dataset) // 5 # 20% of the dataset\n",
    "train_set, eval_set = torch.utils.data.random_split(dataset, [len(dataset) - eval_len, eval_len])\n",
    "\n",
    "loader = DataLoader(eval_set, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def train(model, dataset, batch_size = 128, n_epochs=10):\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model = model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    reg = 1e-6\n",
    "\n",
    "    epoch_iterator = tqdm(\n",
    "            range(n_epochs),\n",
    "            leave=True,\n",
    "            unit=\"epoch\",\n",
    "            postfix={\"tls\": \"%.4f\" % 1},\n",
    "        )\n",
    "\n",
    "    modules = []\n",
    "    for i in model.modules():\n",
    "        if isinstance(i, LinearCD):\n",
    "            modules.append(i)\n",
    "\n",
    "    for _ in epoch_iterator:\n",
    "        reg = min(reg + .5e-5, 1e-3)\n",
    "        for idx, (inputs, targets) in enumerate(loader):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            pred = model(inputs)\n",
    "\n",
    "            reg_value = 0\n",
    "            for module in modules:\n",
    "                reg_value += module.reg()\n",
    "\n",
    "            loss = criterion(pred, targets) + reg*reg_value\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if idx % 10 == 0:\n",
    "                epoch_iterator.set_postfix(tls=\"%.4f\" % loss.item())\n",
    "\n",
    "    print(reg)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:09<00:00, 50.27epoch/s, tls=0.1075]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = Model(512, threshold=.1)\n",
    "model = train(model, train_set, n_epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7144, 0.5733, 0.7956, 0.1486, 0.7911, 0.6613, 0.1491, 0.0516, 0.8569,\n",
       "        0.6134, 0.1162, 0.6057, 0.1518, 0.0117, 0.6140, 0.1717, 0.6347, 0.5819,\n",
       "        0.6631, 0.0370, 0.4127, 0.0559, 0.1536, 0.0157, 0.6988, 0.2164, 0.0713,\n",
       "        0.0347, 0.6146, 0.8080], device='cuda:0', grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sigmoid(model.model[0].logit_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False, False, False,  True, False,\n",
       "       False, False, False, False,  True, False, False, False, False,\n",
       "       False,  True, False,  True, False,  True, False, False,  True,\n",
       "        True, False, False])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sigmoid(model.model[0].logit_p).data.cpu().numpy() < .1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4.3115e-04, 9.5253e-08, 0.0000e+00, 9.3902e-01, 7.7253e-04, 0.0000e+00,\n",
       "        7.3897e-01, 6.7087e-01, 0.0000e+00, 0.0000e+00, 2.6603e-01, 3.2602e-01,\n",
       "        4.3707e-01, 9.6831e-01, 3.3489e-01, 5.3411e-01, 3.0525e-02, 3.0429e-01,\n",
       "        3.2627e-01, 6.2648e-01, 4.1079e-01, 6.3978e-03, 2.3534e-01, 4.4083e-01,\n",
       "        9.6102e-02, 1.7012e-01, 5.9307e-01, 2.9681e-01, 1.4406e-03, 0.0000e+00],\n",
       "       device='cuda:0', grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(10, 30).cuda()\n",
    "model.model[0].concrete_bernoulli(x)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False, False, False,  True, False, False, False, False, False, False,\n",
       "        False, False, False,  True, False, False,  True, False, False, False,\n",
       "        False,  True, False,  True, False,  True,  True,  True, False, False],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "x[0] == model.model[0].concrete_bernoulli(x)[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:['area error' 'worst area' 'worst concave points'\n",
      " 'fractal dimension error' 'mean concave points' 'worst texture'\n",
      " 'worst concavity' 'radius error' 'mean area' 'mean concavity'\n",
      " 'perimeter error' 'worst perimeter' 'compactness error'\n",
      " 'worst compactness' 'worst radius' 'mean texture' 'concave points error'\n",
      " 'texture error' 'mean fractal dimension' 'smoothness error'\n",
      " 'worst symmetry' 'concavity error' 'mean compactness' 'symmetry error'\n",
      " 'worst smoothness' 'mean radius' 'mean smoothness' 'mean perimeter'\n",
      " 'worst fractal dimension' 'mean symmetry']\n",
      "Features Score:tensor([0.0117, 0.0157, 0.0347, 0.0370, 0.0516, 0.0559, 0.0713, 0.1162, 0.1486,\n",
      "        0.1491, 0.1518, 0.1536, 0.1717, 0.2164, 0.4127, 0.5733, 0.5819, 0.6057,\n",
      "        0.6134, 0.6140, 0.6146, 0.6347, 0.6613, 0.6631, 0.6988, 0.7144, 0.7911,\n",
      "        0.7956, 0.8080, 0.8569], device='cuda:0', grad_fn=<SortBackward0>)\n"
     ]
    }
   ],
   "source": [
    "features_score, index = torch.sigmoid(model.model[0].logit_p).sort()\n",
    "\n",
    "features_names = datasets.load_breast_cancer(as_frame=True).data.columns[index.cpu()]\n",
    "\n",
    "print('Features:{}'.format(features_names))\n",
    "print('Features Score:{}'.format(features_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1,\n",
       "        1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "        1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0,\n",
       "        1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "        1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1], device='cuda:0')"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold = .1\n",
    "model.model[0].logit_threshold = torch.tensor(np.log(threshold) - np.log(1. - threshold))\n",
    "model.eval()\n",
    "torch.argmax(torch.softmax(model(x.cuda()), dim=1), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1,\n",
       "        1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "        1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0,\n",
       "        1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "        1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9823, device='cuda:0')"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(torch.argmax(torch.softmax(model(x.cuda()), dim=1), dim=1) == y.cuda()).sum() / len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('HySpecLab')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bc81a3ec444beb1d5a523daf231afa571e79be8a57abb6fe0028623a3d4d7136"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
