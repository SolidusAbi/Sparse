{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import torch \n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functional import sparse_relu\n",
    "from torch.nn.functional import relu as original_relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.float\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "# N is batch size; D_in is input dimension;\n",
    "# H is hidden dimension; D_out is output dimension.\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "\n",
    "# Create random Tensors to hold input and outputs.\n",
    "x = torch.randn(N, D_in, device=device, dtype=dtype)\n",
    "y = torch.randn(N, D_out, device=device, dtype=dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 591.7969360351562\n",
      "199 4.046454906463623\n",
      "299 0.044572532176971436\n",
      "399 0.0010392953408882022\n",
      "499 0.0005109953926876187\n",
      "599 0.0005123534356243908\n",
      "699 0.0005086007877252996\n",
      "799 0.0005088309408165514\n",
      "899 0.000512811413500458\n",
      "999 0.0005103123257867992\n",
      "1099 0.0005138643318787217\n",
      "1199 0.0005146075855009258\n",
      "1299 0.0005172404344193637\n",
      "1399 0.0005144352908246219\n",
      "1499 0.0005151216755621135\n",
      "1599 0.0005138475680723786\n",
      "1699 0.0005151548539288342\n",
      "1799 0.0005157133564352989\n",
      "1899 0.0005128012271597981\n",
      "1999 0.0005169901996850967\n",
      "2099 0.0005134193343110383\n",
      "2199 0.0005141364526934922\n",
      "2299 0.0005133046652190387\n",
      "2399 0.0005134451785124838\n",
      "2499 0.0005136284744367003\n",
      "2599 0.0005109379417262971\n",
      "2699 0.0005130337085574865\n",
      "2799 0.0005114899831824005\n",
      "2899 0.0005113482475280762\n",
      "2999 0.0005125513998791575\n",
      "3099 0.0005152886151336133\n",
      "3199 0.0005115101812407374\n",
      "3299 0.0005109098856337368\n",
      "3399 0.0005128830671310425\n",
      "3499 0.0005099016125313938\n",
      "3599 0.000511359772644937\n",
      "3699 0.0005086479941383004\n",
      "3799 0.0005127431359142065\n",
      "3899 0.0005113001680001616\n",
      "3999 0.0005127028562128544\n",
      "4099 0.000509779725689441\n",
      "4199 0.0005128614138811827\n",
      "4299 0.0005158225540071726\n",
      "4399 0.000519376655574888\n",
      "4499 0.0005189062794670463\n",
      "4599 0.0005186869530007243\n",
      "4699 0.0005162899033166468\n",
      "4799 0.000517895445227623\n",
      "4899 0.0005152198718860745\n",
      "4999 0.0005173716926947236\n"
     ]
    }
   ],
   "source": [
    "# Create random Tensors for weights.\n",
    "w1 = torch.randn(D_in, H, device=device, dtype=dtype, requires_grad=True)\n",
    "w2 = torch.randn(H, D_out, device=device, dtype=dtype, requires_grad=True)\n",
    "\n",
    "learning_rate = 1e-6\n",
    "for t in range(5000):\n",
    "    # To apply our Function, we use Function.apply method. We alias this as 'relu'.\n",
    "    relu = sparse_relu.apply\n",
    "    # relu = original_relu\n",
    "\n",
    "    # Forward pass: compute predicted y using operations; we compute\n",
    "    # ReLU using our custom autograd operation.\n",
    "    y_pred = relu(x.mm(w1), torch.tensor(0.05), torch.tensor(1e-3)).mm(w2)\n",
    "    # y_pred = relu(x.mm(w1)).mm(w2)\n",
    "\n",
    "    # Compute and print loss\n",
    "    loss = (y_pred - y).pow(2).sum()\n",
    "    if t % 100 == 99:\n",
    "        print(t, loss.item())\n",
    "\n",
    "    # Use autograd to compute the backward pass.\n",
    "    loss.backward()\n",
    "\n",
    "    # Update weights using gradient descent\n",
    "    with torch.no_grad():\n",
    "        w1 -= learning_rate * w1.grad\n",
    "        w2 -= learning_rate * w2.grad\n",
    "\n",
    "        # Manually zero the gradients after updating weights\n",
    "        w1.grad.zero_()\n",
    "        w2.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of values closes to 0: 3451; bigger: 2949\n"
     ]
    }
   ],
   "source": [
    "lz = (x.mm(w1)<=0).sum()\n",
    "bz = (x.mm(w1)>0).sum()\n",
    "print('Number of values closes to 0: {}; bigger: {}'.format(lz, bz))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0422, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = x.mm(w1).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 1.,  0.,  0.,  0.,  0.,  1.,  1.,  2.,  2.,  5.,  6.,  9.,  5.,\n",
       "         4., 16.,  7.,  9.,  8.,  4.,  6.,  7.,  5.,  0.,  1.,  1.]),\n",
       " array([-110.60116  , -103.14107  ,  -95.68098  ,  -88.22089  ,\n",
       "         -80.760796 ,  -73.3007   ,  -65.84061  ,  -58.380516 ,\n",
       "         -50.920425 ,  -43.460335 ,  -36.000244 ,  -28.540152 ,\n",
       "         -21.08006  ,  -13.619968 ,   -6.1598763,    1.3002151,\n",
       "           8.760306 ,   16.220398 ,   23.68049  ,   31.140581 ,\n",
       "          38.600674 ,   46.060764 ,   53.520855 ,   60.98095  ,\n",
       "          68.44104  ,   75.90113  ], dtype=float32),\n",
       " <BarContainer object of 25 artists>)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.hist(a[0].detach().cpu().numpy(), bins=25)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fed6d6cd0ea97ce3b2d4e99f7713523d71a847210ef7afa8b6d15b0ad5dcd7d5"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('DeepLearning': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
